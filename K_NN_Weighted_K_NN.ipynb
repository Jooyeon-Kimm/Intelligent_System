{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nKzG4-raIy0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81bf63dd-7616-49b6-8d59-873fa9de1dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc : 0.9123\n",
            "best K:  3\n",
            "prediction validation acc: 1.0000\n",
            "Acc: 0.9649\n"
          ]
        }
      ],
      "source": [
        "# 1. K-NN 을 이용하여 breast cancer 데이터셋 분석하기​\n",
        "\n",
        "############# 1-1) scikit-learn 내장 데이터 셋 불러오기 #############​\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# X (독립변수)와 y(종속변수)로 선언\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# 1-2) 직접 데이터셋 생성​\n",
        "data = pd.DataFrame({\"no_insects\":[True, True, True, False, True, True, True, True, True, False],\n",
        "                     \"no_wilting\": [True, True, True, True, True, True, False, True, True, True],\n",
        "                     \"no_diseases\":[True,True,False,True,True,True,False,False,True,True],\n",
        "                     \"tree_health\":[\"Good\", \"Good\", \"Poor\", \"Good\", \"Good\", \"Good\", \"Poor\", \"Poor\", \"Good\", \"Poor\"]},\n",
        "                    columns=[\"no_insects\",\"no_wilting\",\"no_diseases\",\"tree_health\"])\n",
        "\n",
        "# 1-3) csv 파일 불러오기​\n",
        "df = pd.read_csv(\"/...csv\")\n",
        "\"\"\"\n",
        "\n",
        "############# 2) Data frame으로 데이터 확인​ #############\n",
        "import pandas as pd\n",
        "breast_cancer_df = pd.DataFrame(data=X, columns=cancer.feature_names)\n",
        "breast_cancer_df['label']=y   # 맨끝쪽에 정답 label 추가\n",
        "breast_cancer_df.head()       # 데이터의 상위 5개의 행 출력\n",
        "\n",
        "\n",
        "############# 3) train/test/validation set 분리​ #############\n",
        "# training / test / validation 데이터셋 나누기 (8:1:1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train:test = 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =42, stratify=y)\n",
        "\n",
        "# test data를 1:1 = test: validation\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size =0.5, random_state=42, stratify=y_test)\n",
        "\n",
        "\"\"\"\n",
        "Train_test_split의 파라미터 설명​\n",
        "\n",
        "input data:  X (=cancer.data, 종속 변수)​\n",
        "Output data: y (=cancer.target ,독립변수)​\n",
        "\n",
        "Test_size = 0.2\n",
        "train test 비율을 8:2로 설정​\n",
        "test set을 다시 1:1로 validation set(검증데이터)과 test set으로 나눔​\n",
        "\n",
        "Stratify:\n",
        "y(=cancer.target) , stratify값을 target으로 지정해주면\n",
        "각 클래스를 같은 비율로 train과 test에 할당​\n",
        "즉, 한쪽에 치우치지 않도록​\n",
        "\n",
        "Random_state:\n",
        "일정한 값을 주어, 여러 번 실행되어도 같은 데이터를 추출​\n",
        "\n",
        "​\"\"\"\n",
        "\n",
        "############# 4) Normalization​ #############\n",
        "# 데이터 전처리 (pre-processing)\n",
        "# Standard scaler를 이용해, 모든 feature들이 평균 0, 분산 1인 정규분포를 갖도록 함​\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "std = StandardScaler()\n",
        "std.fit(X_train)\n",
        "X_train_scaled = std.transform(X_train)\n",
        "X_val_scaled = std.transform(X_val)\n",
        "X_test_scaled = std.transform(X_test)\n",
        "\n",
        "\n",
        "############# 5) 모델 생성 및 학습​ #############\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# KNN의 하이퍼파라미터 값 n_neighbors를 1로 설정​\n",
        "knn = KNeighborsClassifier(n_neighbors=1)   # n_neighbors: 이웃의 개수\n",
        "\n",
        "# KNN training\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "############# 6) Evaluation​ #############\n",
        "# 예측 정확도 출력\n",
        "from sklearn import metrics\n",
        "\n",
        "acc = knn.score(X_test_scaled, y_test)\n",
        "print(\"Acc : {:.4f}\".format(acc))\n",
        "\n",
        "\n",
        "############# 7) 최적의 k 찾기​ #############\n",
        "# validation set에서 정확도가 높은 이웃의 개수(k) 찾기\n",
        "# validation set을 통해 최적의 k 찾기​\n",
        "\n",
        "k_range = range(1,50)   # 1~49의 범위 지정\n",
        "scores_list = []        # 리스트 생성\n",
        "\n",
        "# 1-50까지 k에 따른 모델의 정확도를 반복문을 통해서 확인​\n",
        "for k in k_range:\n",
        "  knn = KNeighborsClassifier(n_neighbors = k)\n",
        "  knn.fit(X_train_scaled, y_train)    # 모델 training\n",
        "  y_pred = knn.predict(X_val_scaled)  # test data 예측\n",
        "  scores_list.append(metrics.accuracy_score(y_val, y_pred))\n",
        "  # Scores_list.append를 통해서 scores_list에 1-50까지의 k에 대한 정확도를 리스트에 저장​\n",
        "\n",
        "############# 8) 최적의 k 찾기​ #############\n",
        "# scores_list의 max값을 best_acc 변수에 저장    ​\n",
        "# 1-50까지의 k 값에 대해 validation accuracy가 가장 높은 값이 best_acc에 저장된다​\n",
        "best_acc = max(scores_list)\n",
        "\n",
        "# Best_acc 값에 대응하는 index에 1을 더한 값을 best_k에 저장​\n",
        "# 리스트의 index는 0부터 시작하므로, 1을 더해주어 최적의 k값을 구한다​\n",
        "best_k = scores_list.index(best_acc)+1\n",
        "print(\"best K: \", best_k)\n",
        "print(\"prediction validation acc: {:.4f}\".format(best_acc))\n",
        "\n",
        "\n",
        "############# 9) 최적의 k로 재학습​​ #############\n",
        "# 최적의 k로 test (Validation set을 통해 찾은 best_k값을 이용하여 knn학습​)\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "# KNN training\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 예측 정확도 출력\n",
        "acc = knn.score(X_test_scaled, y_test)\n",
        "print(\"Acc: {:.4f}\".format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Weighted KNN 을 이용하여 breast cancer 데이터셋 분석하기​\n",
        "\n",
        "############# 1-1) scikit-learn 내장 데이터 셋 불러오기 #############​\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# X (독립변수)와 y(종속변수)로 선언\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "\n",
        "############# 2) Data frame으로 데이터 확인​ #############\n",
        "import pandas as pd\n",
        "breast_cancer_df = pd.DataFrame(data=X, columns=cancer.feature_names)\n",
        "breast_cancer_df['label']=y   # 맨끝쪽에 정답 label 추가\n",
        "breast_cancer_df.head()       # 데이터의 상위 5개의 행 출력\n",
        "\n",
        "\n",
        "############# 3) train/test/validation set 분리​ #############\n",
        "# training / test / validation 데이터셋 나누기 (8:1:1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train:test = 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =42, stratify=y)\n",
        "\n",
        "# test data를 1:1 = test: validation\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size =0.5, random_state=42, stratify=y_test)\n",
        "\n",
        "\n",
        "############# 4) Normalization​ #############\n",
        "# 데이터 전처리 (pre-processing)\n",
        "# Standard scaler를 이용해, 모든 feature들이 평균 0, 분산 1인 정규분포를 갖도록 함​\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "std = StandardScaler()\n",
        "std.fit(X_train)\n",
        "X_train_scaled = std.transform(X_train)\n",
        "X_val_scaled = std.transform(X_val)\n",
        "X_test_scaled = std.transform(X_test)\n",
        "\n",
        "\n",
        "############# 5) 모델 생성 및 학습​ #############\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# KNN의 하이퍼파라미터 값 n_neighbors를 1로 설정​\n",
        "knn = KNeighborsClassifier(n_neighbors=1)   # n_neighbors: 이웃의 개수\n",
        "\n",
        "# KNN training\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "############# 6) Evaluation​ #############\n",
        "# 예측 정확도 출력\n",
        "from sklearn import metrics\n",
        "\n",
        "acc = knn.score(X_test_scaled, y_test)\n",
        "print(\"Acc : {:.4f}\".format(acc))\n",
        "\n",
        "\n",
        "############# 7) 최적의 k 찾기​ #############\n",
        "# validation set에서 정확도가 높은 이웃의 개수(k) 찾기\n",
        "# validation set을 통해 최적의 k 찾기​\n",
        "\n",
        "k_range = range(1,50)   # 1~49의 범위 지정\n",
        "scores_list = []        # 리스트 생성\n",
        "\n",
        "for k in k_range:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
        "  knn.fit(X_train_scaled, y_train)    # 모델 training\n",
        "  y_pred = knn.predict(X_val_scaled)  # test data 예측\n",
        "  scores_list.append(metrics.accuracy_score(y_val, y_pred))\n",
        "\n",
        "# KNeighborsClassier의 파라미터 : weights ​\n",
        "# 이웃을 설정할 때 가중치를 주는 방법, ​\n",
        "# “distance”로 설정하면 거리가 가까운 이웃의 영향을 더 많이 받도록 설정 하는 것 ​\n",
        "\n",
        "\n",
        "############# 8) 최적의 k, 최적의 k의 validation accuracy 출력​​ #############\n",
        "best_acc = max(scores_list)\n",
        "best_k = scores_list.index(best_acc)+1\n",
        "print(\"best K: \", best_k)\n",
        "print(\"prediction validation acc: {:.4f}\".format(best_acc))\n",
        "\n",
        "############# 9) 최적의 k로 weighted knn training​​​ #############\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k, weights=\"distance\")\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "############# 10) 예측 정확도 출력​​​​ #############\n",
        "from sklearn import metrics\n",
        "\n",
        "acc = knn.score(X_test_scaled, y_test)\n",
        "print(\"Acc: {:.4f}\".format(acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3omkq_VveqTZ",
        "outputId": "e71c3a30-ff25-4f85-e0a8-9238f07385b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc : 0.9123\n",
            "best K:  3\n",
            "prediction validation acc: 1.0000\n",
            "Acc: 0.9649\n"
          ]
        }
      ]
    }
  ]
}